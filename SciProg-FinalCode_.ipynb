{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case of lack of librosa library --> use !pip install librosa \n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before reading dataset it's better the visit that page: https://zenodo.org/record/1188976#.Yblv3r3P3IU\n",
    "\n",
    "\n",
    "#Each of the RAVDESS files has a unique filename. \n",
    "#The filename consists of a 7-part numerical identifier (e.g., 03-01-03-01-01-01-01.wav). \n",
    "#These identifiers define the stimulus characteristics: \n",
    "\n",
    "#Filename identifiers \n",
    "\n",
    "#Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "#Vocal channel (01 = speech, 02 = song).\n",
    "#Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "#Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "#Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "#Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "#Actor (01 to 24. Odd numbered actors are male, even numbered actors are female)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our study we only take \"Emotion\" and \"Actor\" and \"Gender\" part...\n",
    "\n",
    "# 2-class situation -- only 2 labels male and female ... \n",
    "#This situaition answer this question--> What is the gender of speaker?\n",
    "\n",
    "# 8-class situation -- only 8 labels like fear,happy ... \n",
    "#This situaition answer this question--> What is the fealing of speaker?\n",
    "\n",
    "#16-class situdation -- multilabel for every feelings like fear_male,fear_female,happy_male,_happy female....... \n",
    "#This situaition answer this question--> What is the fealing and gender of speaker?\n",
    "\n",
    "# For further study I want to take #Emotional intensity\" as well...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# reading dataset part\n",
    "\n",
    "#for file in glob.iglob(/Users/alpas/Downloads/Ravdess/Actor_*/*.wav\")\n",
    "   # print(file)\n",
    "###- -------for another way of reading is glob library------------------\n",
    "########################################################################\n",
    "\n",
    "main= r\"C:\\Users\\alpas\\Downloads\\Ravdess\"\n",
    "\n",
    "dataset = os.listdir(main)  # includes file names in main dataset folder --> 24 actors\n",
    "dataset.sort()\n",
    "\n",
    "emotion = []\n",
    "gender = []\n",
    "path = []\n",
    "for i in dataset:\n",
    "    fname = os.listdir(main +\"\\\\\"+ i)\n",
    "    for f in fname:\n",
    "        part = f.split('.')[0].split('-')\n",
    "        emotion.append(int(part[2]))\n",
    "        temp = int(part[6])\n",
    "        if temp%2 == 0:\n",
    "            temp = \"female\"\n",
    "        else:\n",
    "            temp = \"male\"\n",
    "        gender.append(temp)\n",
    "        path.append(main + \"\\\\\"+i + '\\\\' +  f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# DATA EDITING PART  #############   2 CLASS SITUATION #######################    \n",
    "    # after reading it, trying to put these in to table/matrix\n",
    "dataset2C_df = pd.DataFrame(gender)\n",
    "        # naming the feature\n",
    "dataset2C_df.columns = ['gender']\n",
    "\n",
    "    # path is also important, when extracting features, it'll show the files\n",
    "dataset2C_df = pd.concat([dataset2C_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "\n",
    "dataset2C_df.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# DATA EDITING PART  #############   8 CLASS SITUATION #######################    \n",
    "    # after reading it, trying to put these in to table/matrix\n",
    "dataset8C_df = pd.DataFrame(emotion)\n",
    "        # there are 8 classes... Making it categorical data to make more sense\n",
    "dataset8C_df = dataset8C_df.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
    "        # naming the features\n",
    "dataset8C_df.columns = ['emotion']\n",
    "\n",
    "    # path is also important, when extracting features, it'll show the files\n",
    "dataset8C_df = pd.concat([dataset8C_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "\n",
    "dataset8C_df.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  ############# DATA EDITING PART  #############   16 CLASS SITUATION #######################\n",
    "    ## Note: There are 8 different emotion labels and 2 gender labels. By combining these two feature I created 16 class\n",
    "    ## Eg. neutral --> neutral_male and neutral_female\n",
    "    \n",
    "    \n",
    "    \n",
    "    # after reading it, trying to put these in to table/matrix\n",
    "dataset16C_df = pd.DataFrame(emotion)\n",
    "        # there are 8 classes... Making it categorical data to make more sense\n",
    "dataset16C_df = dataset16C_df.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
    "        # there are also another feature on this data set : male or female?\n",
    "dataset16C_df = pd.concat([pd.DataFrame(gender),dataset16C_df],axis=1)\n",
    "        # naming the features\n",
    "dataset16C_df.columns = ['gender','emotion']\n",
    "        # making it new column that combine gender and emotion ------->>>>>> WITH THIS LINE THERE BECAMES 16 CLASS\n",
    "dataset16C_df['labels'] =dataset16C_df.gender + '_' + dataset16C_df.emotion \n",
    "    # path is also important, when extracting features, it'll show the files\n",
    "dataset16C_df = pd.concat([dataset16C_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "dataset16C_df = dataset16C_df.drop(['gender', 'emotion'], axis=1)\n",
    "dataset16C_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# DATA EDITING PART  #############   16 CLASS SITUATION #######################\n",
    "### CREATING CSV FILE for 16-Class data \n",
    "\n",
    "df = pd.concat([dataset16C_df], axis = 0)\n",
    "print(df.labels.value_counts())\n",
    "df.head()\n",
    "df.to_csv(\"Data_path16Class.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# DATA EDITING PART  #############   8 CLASS SITUATION #######################\n",
    "### CREATING CSV FILE for 8-class data\n",
    "\n",
    "df = pd.concat([dataset8C_df], axis = 0)\n",
    "print(df.emotion.value_counts())\n",
    "df.head()\n",
    "df.to_csv(\"Data_path8Class.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# DATA EDITING PART  #############   2 CLASS SITUATION #######################\n",
    "### CREATING CSV FILE for 2-class data\n",
    "\n",
    "df = pd.concat([dataset2C_df], axis = 0)\n",
    "print(df.gender.value_counts())\n",
    "df.head()\n",
    "df.to_csv(\"Data_path2Class.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualisation by bar plot -- for 8 class situation\n",
    "height = [96, 192, 192, 192, 192,192,192,192]\n",
    "bars = ('neutral', 'calm','happy','sad','angry','fear','disgust','surprise')\n",
    "y_pos = np.arange(len(bars))\n",
    "\n",
    "# Create bars\n",
    "plt.bar(y_pos, height)\n",
    "\n",
    "# Create names on the x-axis\n",
    "plt.xticks(y_pos, bars)\n",
    "\n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some examples from emotions ---> fear \n",
    "fname = main + '\\\\Actor_14\\\\03-01-06-02-02-01-14.wav'  \n",
    "data, rate = librosa.load(fname)\n",
    "plt.figure(figsize=(18, 7))  \n",
    "librosa.display.waveplot(data, sr=rate,color='#00E7DB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some examples from emotions ---> anger\n",
    "fname2 =main+ \"\\\\Actor_08\\\\03-01-05-02-01-01-08.wav\" \n",
    "data, rate = librosa.load(fname2)\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=rate,color='#C00808') ## with the red colour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some examples from emotions ---> happy\n",
    "fname3 =main+ \"\\\\Actor_01\\\\03-01-03-01-01-01-01.wav\" \n",
    "data, rate = librosa.load(fname2)\n",
    "plt.figure(figsize=(18, 7))\n",
    "librosa.display.waveplot(data, sr=rate,color='#F19C0E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I've created CSV for all situation... Depends on your wish you can use it (2 , 8 or 16-class)\n",
    "\n",
    "############################## !!!IMPORTANT!!!  ###########################\n",
    "#For proper work of code,from this point after you chose dataset you should know that...\n",
    "#... you can't use data combination part with others. What I mean if you choose 8-class data here...\n",
    "#...in the next section you should run the relevant combination and training with the code.\n",
    "\n",
    "# Ex: Data_path8Class ---> line with that comment \"### FOR COMBINATION OF FEATURES ####  8 Classes\" and -->\n",
    "# ### TEST TRAIN DATA SPLIT FOR 8-CLASS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#full_path = pd.read_csv(r\"C:\\Users\\alpas\\OneDrive\\Desktop\\Lectures 20-21 Autumn\\(PHYS4038 UNUK)Scientific Programming in Python  (AUT1 21-22)\\SPP\\Data_path2Class.csv\")\n",
    "full_path = pd.read_csv(r\"C:\\Users\\alpas\\OneDrive\\Desktop\\Lectures 20-21 Autumn\\(PHYS4038 UNUK)Scientific Programming in Python  (AUT1 21-22)\\SPP\\Data_path8Class.csv\")\n",
    "#full_path = pd.read_csv(r\"C:\\Users\\alpas\\OneDrive\\Desktop\\Lectures 20-21 Autumn\\(PHYS4038 UNUK)Scientific Programming in Python  (AUT1 21-22)\\SPP\\Data_path16Class.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This feature extraction function is for single audio file to visualize features \n",
    "def extract_feature(path):\n",
    "    \n",
    "    X,_ = librosa.load(path)\n",
    "    stft = librosa.amplitude_to_db(abs(librosa.stft(X)))\n",
    "    mfcc = librosa.feature.mfcc(y=X, sr=rate, n_mfcc=13)\n",
    "    chroma = librosa.feature.chroma_stft(y=X, sr=13)\n",
    "    zeroC= librosa.feature.zero_crossing_rate(y=X)\n",
    "    return stft,mfcc,chroma,zeroC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = main +\"\\\\Actor_08\\\\03-01-05-02-02-01-08.wav\"\n",
    "X, rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)  \n",
    "stft,mfcc,chroma,zeroC = extract_feature(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero Crossing Rate\n",
    "plt.figure(figsize=(15, 7))\n",
    "librosa.display.specshow(zeroC, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('ZeroC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCC\n",
    "plt.figure(figsize=(20, 30))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(mfcc, x_axis='time')\n",
    "plt.ylabel('mfcc')\n",
    "plt.title(\"MFCC\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stft\n",
    "plt.figure(figsize=(10, 10))\n",
    "librosa.display.specshow(stft, x_axis='time')\n",
    "plt.ylabel('stft')\n",
    "plt.title('STFT')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chroma\n",
    "plt.figure(figsize=(15, 4))\n",
    "librosa.display.specshow(chroma, y_axis='chroma', x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('Chroma')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## FEATURE EXTRACTION FUNCTIONS ################# (MFCC,STFT,CHROMA,MEL,ZCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_feature_exract():\n",
    "    mf = pd.DataFrame(columns=['MFCC feature'])\n",
    "\n",
    "    counter=0\n",
    "    for index,path in enumerate(full_path.path):\n",
    "        \n",
    "        X, rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=22050,offset=0.5)\n",
    "        rate = np.array(rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=rate, n_mfcc=20).T,axis=0)  # mean as the feature\n",
    "        mf.loc[counter] = [mfccs]\n",
    "        counter+=1\n",
    "            \n",
    "    print(len(mf))        \n",
    "    return mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stft_feature_exract():\n",
    "    stf = pd.DataFrame(columns=['STFT feature'])\n",
    "\n",
    "    # loop feature extraction over the entire dataset\n",
    "    counter=0\n",
    "    for index,path in enumerate(full_path.path):\n",
    "        \n",
    "        X, rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=22050,offset=0.5)\n",
    "        rate = np.array(rate)\n",
    "        stft = np.mean(librosa.amplitude_to_db(abs(librosa.stft(X,hop_length=64))).T,axis=0)  # mean as the feature\n",
    "        stf.loc[counter]=[stft]\n",
    "        counter+=1\n",
    "            \n",
    "    print(len(stf))        \n",
    "    return stf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chroma_feature_exract():\n",
    "    chr = pd.DataFrame(columns=['CHROMA feature'])\n",
    "\n",
    "    # loop feature extraction over the entire dataset\n",
    "    counter=0\n",
    "    for index,path in enumerate(full_path.path):\n",
    "        \n",
    "        X, rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=22050,offset=0.5)\n",
    "        rate = np.array(rate)\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(y=X, sr=rate,n_chroma=20).T,axis=0)  # mean as the feature\n",
    "        chr.loc[counter]=[chroma]\n",
    "        counter+=1\n",
    "    \n",
    "    print(len(chr))        \n",
    "    return chr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_feature_exract():\n",
    "    me = pd.DataFrame(columns=['MEL feature'])\n",
    "\n",
    "    # loop feature extraction over the entire dataset\n",
    "    counter=0\n",
    "    for index,path in enumerate(full_path.path):\n",
    "        \n",
    "        X, rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=22050,offset=0.5)\n",
    "        rate = np.array(rate)\n",
    "        mel = np.mean(librosa.feature.melspectrogram(X, sr=rate,n_mels=20).T, axis=0)  # mean as the feature\n",
    "        me.loc[counter]=[mel]\n",
    "        counter+=1\n",
    "    \n",
    "    print(len(me))        \n",
    "    return me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zcr_feature_exract():\n",
    "    zcr = pd.DataFrame(columns=['ZCR feature'])\n",
    "\n",
    "    # loop feature extraction over the entire dataset\n",
    "    counter=0\n",
    "    for index,path in enumerate(full_path.path):\n",
    "        \n",
    "        X, rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=22050,offset=0.5)\n",
    "        rate = np.array(rate)\n",
    "        zeroC = np.mean(librosa.feature.zero_crossing_rate(y=X).T, axis=0)  # mean as the feature\n",
    "        zcr.loc[counter]=[zeroC]\n",
    "        counter+=1\n",
    "        \n",
    "    print(len(zcr))        \n",
    "    return zcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "########## FEATURE EXTRACTIONS ################# (MFCC,STFT,CHROMA,MEL,ZCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Mfcc_f= mfcc_feature_exract()\n",
    "Mfcc_feature = pd.concat([full_path,pd.DataFrame(Mfcc_f['MFCC feature'].values.tolist())],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mfcc_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcr_f= zcr_feature_exract()\n",
    "zcr_feature= pd.concat([full_path,pd.DataFrame(zcr_f['ZCR feature'].values.tolist())],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcr_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mel_f= mel_feature_exract()\n",
    "mel_feature = pd.concat([full_path,pd.DataFrame(mel_f['MEL feature'].values.tolist())],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CH_f= chroma_feature_exract()\n",
    "CH_feature=pd.concat([full_path,pd.DataFrame(CH_f['CHROMA feature'].values.tolist())],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CH_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_f= stft_feature_exract()\n",
    "stft_feature=pd.concat([full_path,pd.DataFrame(stft_f['STFT feature'].values.tolist(),)],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stft_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR COMBINATION OF FEATURES ####  2 Classes\n",
    "### usage of this part pd.concat([feature1,feature2,feature3........], axis=1)\n",
    "A=pd.concat([Mfcc_feature,stft_feature], axis=1)\n",
    "B=A.drop(columns=['path'])  # to avoid dublicate of path columns\n",
    "B=B.drop(columns=['gender']) #  # to avoid dublicate of emotion columns\n",
    "new_feature_set2=full_path.join(B)\n",
    "new_feature_set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR COMBINATION OF FEATURES ####  8 Classes\n",
    "### usage of this part pd.concat([feature1,feature2,feature3........], axis=1)\n",
    "A=pd.concat([Mfcc_feature,CH_feature], axis=1)\n",
    "B=A.drop(columns=['path'])  # to avoid dublicate of path columns\n",
    "B=B.drop(columns=['emotion']) #  # to avoid dublicate of emotion columns\n",
    "new_feature_set8=full_path.join(B)\n",
    "new_feature_set8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR COMBINATION OF FEATURES ####  16 Classes\n",
    "### usage of this part pd.concat([feature1,feature2,feature3........], axis=1)\n",
    "A=pd.concat([Mfcc_feature,stft_feature], axis=1)\n",
    "B=A.drop(columns=['path'])  # to avoid dublicate of path columns\n",
    "B=B.drop(columns=['labels']) #  # to avoid dublicate of labels columns\n",
    "new_feature_set8=full_path.join(B)\n",
    "new_feature_set8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST TRAIN DATA SPLIT FOR 2-CLASS dataset\n",
    "### which feature set do you want to use? for individual features use name defined above like \"Mfcc_feature\"\n",
    "# for combination of feature set use new_feature_set2,new_feature_set8 or new_feature_set16\n",
    "#  train_test_split(nameoftheset.drop(['gender','path'],axis=1)\n",
    "                                        ## nameoftheset.emotion\n",
    "X_train, X_test, y_train, y_test = train_test_split(stft_feature.drop(['gender','path'],axis=1)\n",
    "                                                    , stft_feature.gender\n",
    "                                                    , test_size=0.20\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=0)\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std\n",
    "\n",
    "## for softmax normalization uncomment below\n",
    "\n",
    "####   SOFTMAX NORMALIZATION  --->  np.exp(x)/sum(np.exp(x))\n",
    "#X_train=np.exp(X_train)/sum(np.exp(X_train))\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST TRAIN DATA SPLIT FOR 8-CLASS dataset\n",
    "### which feature set do you want to use? for individual features use name defined above like \"Mfcc_feature\"\n",
    "# for combination of feature set use new_feature_set2,new_feature_set8 or new_feature_set16\n",
    "#  train_test_split(nameoftheset.drop(['emotion','path'],axis=1)\n",
    "                                        ## nameoftheset.emotion\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_feature_set8.drop(['emotion','path'],axis=1)\n",
    "                                                    , new_feature_set8.emotion\n",
    "                                                    , test_size=0.20\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=0)\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std\n",
    "\n",
    "## for softmax normalization uncomment below\n",
    "\n",
    "####   SOFTMAX NORMALIZATION  --->  np.exp(x)/sum(np.exp(x))\n",
    "#X_train=np.exp(X_train)/sum(np.exp(X_train))\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST TRAIN DATA SPLIT FOR 16-CLASS dataset\n",
    "### which feature set do you want to use? for individual features use name defined above like \"Mfcc_feature\"\n",
    "# for combination of feature set use new_feature_set2, new_feature_set8 or new_feature_set16\n",
    "#  train_test_split(nameoftheset.drop(['emotion','labels'],axis=1)\n",
    "                                        ## nameoftheset.labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_feature_set16.drop(['emotion','labels'],axis=1)\n",
    "                                                    , new_feature_set16.labels\n",
    "                                                    , test_size=0.20\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=0)\n",
    "\n",
    "# This is standard normalization\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std\n",
    "\n",
    "## for softmax normalization uncomment below\n",
    "\n",
    "####   SOFTMAX NORMALIZATION  --->  np.exp(x)/sum(np.exp(x))\n",
    "#X_train=np.exp(X_train)/sum(np.exp(X_train))\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MLP Classifier #####\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model=MLPClassifier(alpha=0.01, batch_size=128, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the accuracy \n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: %{:.2f}\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVM Classifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "accuracy2=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy: %{:.2f}\".format(accuracy2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KNN Classifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=7)\n",
    "neigh.fit(X_train,y_train)\n",
    "print('Score:', neigh.score(X_train,y_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
